{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self,device,acc,ppv,sensi,auroc,aurocPlot,auprc,auprcPlot,callb,callbPlot):\n",
    "        super(Loss, self).__init__()\n",
    "        self.classify_loss = nn.BCELoss()\n",
    "        self.device=device\n",
    "        self.acc=acc\n",
    "        self.ppv=ppv\n",
    "        self.sensi=sensi\n",
    "        self.auroc=auroc\n",
    "        self.aurocPlot=aurocPlot\n",
    "        self.auprc=auprc\n",
    "        self.auprcPlot=auprcPlot\n",
    "        self.callb=callb\n",
    "        self.callbPlot=callbPlot\n",
    "\n",
    "    def forward(self, prob, labels, train=True):\n",
    "        classify_loss=NA \n",
    "        auc,apr=NA\n",
    "        base=NA\n",
    "        accur=NA\n",
    "        prec=NA\n",
    "        recall=NA\n",
    "        spec=NA\n",
    "        npv_val=NA\n",
    "        ECE=NA\n",
    "        MCE=NA\n",
    "        \n",
    "        #prob = prob.data.cpu().numpy()\n",
    "        #print(torch.sum(torch.isnan(prob)))\n",
    "        pos_ind = labels >= 0.5\n",
    "        neg_ind = labels < 0.5\n",
    "        pos_label = labels[pos_ind]\n",
    "        neg_label = labels[neg_ind]\n",
    "        pos_prob = prob[pos_ind]\n",
    "        neg_prob = prob[neg_ind]\n",
    "        pos_loss, neg_loss = 0, 0\n",
    "\n",
    "        #################           BCE            #######################\n",
    "        if len(pos_prob):\n",
    "            pos_prob=pos_prob.to(self.device)\n",
    "            pos_label=pos_label.to(self.device)\n",
    "            pos_loss = self.classify_loss(pos_prob, pos_label) \n",
    "       \n",
    "        if len(neg_prob):\n",
    "            neg_prob=neg_prob.to(self.device)\n",
    "            neg_label=neg_label.to(self.device)\n",
    "            neg_loss = self.classify_loss(neg_prob, neg_label)\n",
    "        \n",
    "        classify_loss = pos_loss + neg_loss\n",
    "        # classify_loss = self.classify_loss(prob, labels)\n",
    "        \n",
    "        \n",
    "        #################           AUROC            #######################\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        prob = prob.data.cpu().numpy()\n",
    "        if(self.auroc):\n",
    "            fpr, tpr, threshholds = metrics.roc_curve(labels, prob)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "        if(self.aurocPlot):\n",
    "            auroc_plot(label, prob)\n",
    "        \n",
    "        #################           AUPRC            #######################\n",
    "        if(self.auprc):\n",
    "            base = ((labels==1).sum())/labels.shape[0]\n",
    "\n",
    "            precision, recall, thresholds = metrics.precision_recall_curve(labels, prob)\n",
    "            apr = metrics.auc(recall, precision)\n",
    "        \n",
    "        \n",
    "        # stati number\n",
    "        prob1 = prob >= 0.5\n",
    "        #print(prob)\n",
    "        \n",
    "        pos_l = (labels==1).sum()\n",
    "        neg_l = (labels==0).sum()\n",
    "        pos_p = (prob1 + labels == 2).sum()#how many positives are predicted positive#####TP\n",
    "        neg_p = (prob1 + labels == 0).sum()#True negatives\n",
    "        prob2 = prob < 0.5\n",
    "        fn    = (prob2 + labels==2).sum()\n",
    "        fp    = (prob2 + labels==0).sum()\n",
    "        #print(classify_loss, pos_p, pos_l, neg_p, neg_l)\n",
    "        \n",
    "        #################           Accuracy            #######################\n",
    "        if(self.acc):\n",
    "            accur=metrics.accuracy_score(labels,prob>=0.5)\n",
    "        \n",
    "        #################           Precision/PPV  (TP/(TP+FP))         #######################\n",
    "        if(self.ppv):\n",
    "            prec=metrics.precision_score(labels,prob>=0.5)\n",
    "        \n",
    "        #################           Recall/TPR/Sensitivity(TP/(TP+FN))          #######################\n",
    "        if(self.sensi):\n",
    "            recall=pos_p/(pos_p+fn)\n",
    "        #################           Specificity/TNR  (TN/(TN+FP))         #######################\n",
    "        if(self.tnr):\n",
    "            spec=neg_p/(neg_p+fp)\n",
    "        \n",
    "        #################           NPV  (TN/(TN+FN))         #######################\n",
    "        if(self.npv):\n",
    "            npv_val=neg_p/(neg_p+fn)\n",
    "        #################           Callibration         #######################\n",
    "        if(self.callb):\n",
    "            if(callbPlot):\n",
    "                ECE, MCE = calb_metrics(prob,val_labels,TRUE)\n",
    "            else:\n",
    "                ECE, MCE = calb_metrics(prob,val_labels,FALSE)\n",
    "        \n",
    "        #################           Fairness         #######################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return [classify_loss, auc,apr,base,accur,prec,recall,spec,npv_val,ECE,MCE]\n",
    "    \n",
    "\n",
    "    def auroc_plot(label, pred):\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "\n",
    "        pred = val_prob\n",
    "        label = val_labels\n",
    "        fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "        auc = metrics.roc_auc_score(label, pred)\n",
    "        plt.plot(fpr, tpr, label=f'Logistic regression, auc = {str(round(auc,3))}')\n",
    "\n",
    "\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.title(\"AUC-ROC for two models\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"auroc_plot.png\")\n",
    "        #plt.show()\n",
    "        \n",
    "    def calb_curve(bins,bin_accs,ECE, MCE):\n",
    "        import matplotlib.patches as mpatches\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = fig.gca()\n",
    "\n",
    "        # x/y limits\n",
    "        ax.set_xlim(0, 1.05)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        # x/y labels\n",
    "        plt.xlabel('Confidence')\n",
    "        plt.ylabel('Accuracy')\n",
    "\n",
    "        # Create grid\n",
    "        ax.set_axisbelow(True) \n",
    "        ax.grid(color='gray', linestyle='dashed')\n",
    "\n",
    "        # Error bars\n",
    "        plt.bar(bins, bins,  width=0.1, alpha=0.3, edgecolor='black', color='r', hatch='\\\\')\n",
    "\n",
    "        # Draw bars and identity line\n",
    "        plt.bar(bins, bin_accs, width=0.1, alpha=1, edgecolor='black', color='b')\n",
    "        plt.plot([0,1],[0,1], '--', color='gray', linewidth=2)\n",
    "\n",
    "        # Equally spaced axes\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "        # ECE and MCE legend\n",
    "        ECE_patch = mpatches.Patch(color='green', label='ECE = {:.2f}%'.format(ECE*100))\n",
    "        MCE_patch = mpatches.Patch(color='red', label='MCE = {:.2f}%'.format(MCE*100))\n",
    "        plt.legend(handles=[ECE_patch, MCE_patch])\n",
    "        plt.savefig(\"callibration_plot.png\")\n",
    "        #plt.show()\n",
    "        \n",
    "    def calb_bins(preds,labels):\n",
    "        # Assign each prediction to a bin\n",
    "        num_bins = 10\n",
    "        bins = np.linspace(0.1, 1, num_bins)\n",
    "        binned = np.digitize(preds, bins)\n",
    "\n",
    "        # Save the accuracy, confidence and size of each bin\n",
    "        bin_accs = np.zeros(num_bins)\n",
    "        bin_confs = np.zeros(num_bins)\n",
    "        bin_sizes = np.zeros(num_bins)\n",
    "\n",
    "        for bin in range(num_bins):\n",
    "        bin_sizes[bin] = len(preds[binned == bin])\n",
    "        if bin_sizes[bin] > 0:\n",
    "            bin_accs[bin] = (labels[binned==bin]).sum() / bin_sizes[bin]\n",
    "            bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
    "\n",
    "        return bins, binned, bin_accs, bin_confs, bin_sizes\n",
    "\n",
    "\n",
    "    def calb_metrics(preds,labels,curve):\n",
    "        ECE = 0\n",
    "        MCE = 0\n",
    "        bins, _, bin_accs, bin_confs, bin_sizes = calb_bins(preds,labels)\n",
    "        \n",
    "        for i in range(len(bins)):\n",
    "        abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
    "        ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
    "        MCE = max(MCE, abs_conf_dif)\n",
    "        if curve:\n",
    "            calb_curve(bins,bin_accs,ECE, MCE)\n",
    "        return ECE, MCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-newspaper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:DSRA] *",
   "language": "python",
   "name": "conda-env-DSRA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
